{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Imports",
   "id": "2e3c13fe58bbba2e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T09:02:33.567851Z",
     "start_time": "2025-04-18T09:02:33.551977Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from typing import Generator, List, Optional, Tuple\n",
    "\n",
    "import cv2\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from torchvision.datasets import CIFAR10"
   ],
   "id": "db47bd72fb4a4a24",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Constants\n",
   "id": "f3f16a8b88a01e4f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T09:02:33.579009Z",
     "start_time": "2025-04-18T09:02:33.577310Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MAX_ITERATIONS: int = 10000\n",
    "RESOLUTION: Tuple[int, int] = (64, 64)\n",
    "N_COMPONENTS = 500"
   ],
   "id": "6cd041df4c21fc43",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# SVC Model",
   "id": "9cebfe581159dd86"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "LFW dataset loading (positive class)",
   "id": "447101bb0a26ea35"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T09:02:33.591104Z",
     "start_time": "2025-04-18T09:02:33.588703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_lfw_positive_images(target_size: Tuple[int, int] = RESOLUTION) -> Tuple[np.ndarray, int]:\n",
    "    \"\"\"\n",
    "    Loads the LFW dataset, extracts positive images, and resizes them to the target size.\n",
    "\n",
    "    :param target_size: The target size (width, height) for resizing the images.\n",
    "    :return: A tuple containing the NumPy array of resized positive images and the count of positive images.\n",
    "    \"\"\"\n",
    "    lfw = fetch_lfw_people(color=True, funneled=True, resize=1.0)\n",
    "    pos_img: np.ndarray = lfw.images\n",
    "    pos_cnt: int = pos_img.shape[0]\n",
    "\n",
    "    pos_resized: np.ndarray = np.array([cv2.resize(img, target_size) for img in pos_img])\n",
    "    return pos_resized, pos_cnt"
   ],
   "id": "2f2395595188ea67",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T09:02:35.956127Z",
     "start_time": "2025-04-18T09:02:33.602338Z"
    }
   },
   "cell_type": "code",
   "source": [
    "positive_images: np.ndarray\n",
    "positive_count: int\n",
    "positive_images, positive_count = load_lfw_positive_images(target_size=RESOLUTION)\n",
    "print(positive_count)"
   ],
   "id": "43ddfe140c53284d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13233\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "CIFAR-10 dataset loading (negative class)",
   "id": "5718066e5d174747"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T09:02:35.967205Z",
     "start_time": "2025-04-18T09:02:35.965017Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_cifar10_negative_images(data_path: str = './data', target_size: Tuple[int, int] = RESOLUTION) -> Tuple[np.ndarray, int]:\n",
    "    \"\"\"\n",
    "    Loads the CIFAR-10 dataset, resizes images to the target size, and extracts negative images as a single NumPy array.\n",
    "\n",
    "    :param data_path: Path to download and store the CIFAR-10 dataset.\n",
    "    :param target_size: The target size (width, height) for resizing the images.\n",
    "    :return: A tuple containing the NumPy array of resized negative images and their count.\n",
    "    \"\"\"\n",
    "    cifar10_dataset = CIFAR10(\n",
    "        root=data_path,\n",
    "        train=True,\n",
    "        download=True\n",
    "    )\n",
    "\n",
    "    neg_img: np.ndarray = np.array([\n",
    "        cv2.resize(np.array(img), target_size) for img, _ in cifar10_dataset\n",
    "    ])\n",
    "    neg_cnt: int = len(neg_img)\n",
    "\n",
    "    return neg_img, neg_cnt"
   ],
   "id": "3d828442360fa9d",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T09:02:37.550179Z",
     "start_time": "2025-04-18T09:02:35.975380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "negative_images: np.ndarray\n",
    "negative_count: int\n",
    "negative_images, negative_count = load_cifar10_negative_images()\n",
    "print(negative_count)"
   ],
   "id": "c5a9ec9e4145d1b6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "HOG feature extraction",
   "id": "ebef3f52b93c7ed0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T09:02:37.560704Z",
     "start_time": "2025-04-18T09:02:37.558437Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_hog_features(image: np.ndarray,\n",
    "                         pixels_per_cell: Tuple[int, int] = (8, 8),\n",
    "                         cells_per_block: Tuple[int, int] = (2, 2),\n",
    "                         orientations: int = 9) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extracts HOG (Histogram of Oriented Gradients) descriptors from an image.\n",
    "\n",
    "    :param image: The input image as a NumPy array.\n",
    "    :param pixels_per_cell: The size of each cell in pixels (width, height).\n",
    "    :param cells_per_block: The number of cells per block (width, height).\n",
    "    :param orientations: The number of orientation bins for the histograms.\n",
    "    :return: The HOG feature vector as a NumPy array.\n",
    "    \"\"\"\n",
    "    if len(image.shape) > 2:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    features, _ = hog(image, orientations=orientations,\n",
    "                      pixels_per_cell=pixels_per_cell,\n",
    "                      cells_per_block=cells_per_block,\n",
    "                      block_norm='L2-Hys', visualize=True)\n",
    "    return features"
   ],
   "id": "7b1facb497952393",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Loading the dataset",
   "id": "60a5ab0154a5b667"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T09:02:37.579363Z",
     "start_time": "2025-04-18T09:02:37.576712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_dataset(pos_img: np.ndarray,\n",
    "                 neg_img: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Load dataset with optimized parallel HOG feature extraction.\n",
    "\n",
    "    :param pos_img: Array of positive class images.\n",
    "    :param neg_img: Array of negative class images.\n",
    "    :return: A tuple containing the feature matrix (data_X) and the label vector (labels_y).\n",
    "    \"\"\"\n",
    "    total_images = len(pos_img) + len(neg_img)\n",
    "    feature_length = len(extract_hog_features(pos_img[0]))\n",
    "\n",
    "    data_X = np.zeros((total_images, feature_length), dtype=np.float32)\n",
    "    labels_y = np.zeros(total_images, dtype=np.int32)\n",
    "\n",
    "    n_pos = len(pos_img)\n",
    "    for i, img in enumerate(pos_img):\n",
    "        data_X[i] = extract_hog_features(img)\n",
    "\n",
    "    labels_y[:n_pos] = 1\n",
    "\n",
    "    for i, img in enumerate(neg_img):\n",
    "        data_X[i + n_pos] = extract_hog_features(img)\n",
    "\n",
    "    return data_X, labels_y"
   ],
   "id": "6abbc16d08cd458d",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-04-18T09:02:37.589813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X: np.ndarray\n",
    "Y: np.ndarray\n",
    "X, Y = load_dataset(positive_images, negative_images)\n",
    "print(\"Dataset size:\", X.shape, Y.shape)"
   ],
   "id": "250d60d765e072ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Standard Scaling and Dimensionality Reduction (PCA)",
   "id": "70cf09d7125bb7a1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "scaler: StandardScaler = StandardScaler()\n",
    "X_scaled: np.ndarray = scaler.fit_transform(X)\n",
    "\n",
    "reducer: PCA = PCA(n_components=N_COMPONENTS)\n",
    "X_reduced: np.ndarray = reducer.fit_transform(X)\n",
    "\n",
    "print(\"Feature size\", X_reduced.shape)"
   ],
   "id": "47f7cf2e292ce38d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Training the SVC (already trained, can be loaded from the commented line)",
   "id": "329394b86f7c196e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if not os.path.exists(\"model\"):\n",
    "    os.makedirs(\"model\")\n",
    "\n",
    "filename: str = \"model/svm.joblib\""
   ],
   "id": "89112970c9fb0ad0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# svc: SVC = joblib.load(filename)\n",
    "\n",
    "svc: SVC = SVC(kernel=\"linear\", max_iter=MAX_ITERATIONS)\n",
    "svc.fit(X_reduced, Y)\n",
    "\n",
    "joblib.dump(svc, filename)\n",
    "\n",
    "pred_train: np.ndarray = svc.predict(X_reduced)\n",
    "print(\"Classification report (training data):\")\n",
    "print(classification_report(Y, pred_train))"
   ],
   "id": "5b53663f7259fefc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Face detection pipeline",
   "id": "db91c960738b234c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Image pyramid generator, for image scaling",
   "id": "19b7e06dda27db95"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def image_pyramid(image: np.ndarray, scale: float = 1.5, minSize: Tuple[int, int] = RESOLUTION) -> Generator[np.ndarray, None, None]:\n",
    "    \"\"\"\n",
    "    Generates an image pyramid.\n",
    "\n",
    "    :param image: The original image as a NumPy array.\n",
    "    :param scale: The scaling factor for resizing the image.\n",
    "    :param minSize: The minimum size (width, height) at which resizing stops.\n",
    "    :yield: The resized image as a NumPy array.\n",
    "    \"\"\"\n",
    "    yield image\n",
    "    while True:\n",
    "        w: int = int(image.shape[1] / scale)\n",
    "        h: int = int(image.shape[0] / scale)\n",
    "        image = cv2.resize(image, (w, h))\n",
    "        if image.shape[0] < minSize[1] or image.shape[1] < minSize[0]:\n",
    "            break\n",
    "        yield image"
   ],
   "id": "951e1c5e692bc6c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Sliding window generator, for extracting patches from the image",
   "id": "2958cef2e8d46e8a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def sliding_window(image: np.ndarray, stepSize: int, windowSize: Tuple[int, int]) -> Generator[Tuple[int, int, np.ndarray], None, None]:\n",
    "    \"\"\"\n",
    "    Iterates over an image with a sliding window.\n",
    "\n",
    "    :param image: The image to iterate over as a NumPy array.\n",
    "    :param stepSize: The step size for moving the window.\n",
    "    :param windowSize: The size of the window (width, height).\n",
    "    :yield: The coordinates (x, y) and the extracted patch as a NumPy array.\n",
    "    \"\"\"\n",
    "    for y in range(0, image.shape[0] - windowSize[1] + 1, stepSize):\n",
    "        for x in range(0, image.shape[1] - windowSize[0] + 1, stepSize):\n",
    "            yield x, y, image[y:y + windowSize[1], x:x + windowSize[0]]"
   ],
   "id": "685353dd9de7406f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Non-Maximum Suppression (NMS)",
   "id": "72ad9d1a29ebcfb5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def non_max_suppression(boxes: List[Tuple[int, int, int, int]], overlapThresh: float = 0.3) -> List[Tuple[int, int, int, int]]:\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "\n",
    "    boxes_np = np.array(boxes)\n",
    "    x1 = boxes_np[:, 0]\n",
    "    y1 = boxes_np[:, 1]\n",
    "    x2 = x1 + boxes_np[:, 2]\n",
    "    y2 = y1 + boxes_np[:, 3]\n",
    "\n",
    "    areas = (x2 - x1) * (y2 - y1)\n",
    "    indexes = np.argsort(areas)[::-1]\n",
    "\n",
    "    picked = []\n",
    "    while len(indexes) > 0:\n",
    "        i = indexes[0]\n",
    "        picked.append(i)\n",
    "\n",
    "        xx1 = np.maximum(x1[i], x1[indexes[1:]])\n",
    "        yy1 = np.maximum(y1[i], y1[indexes[1:]])\n",
    "        xx2 = np.minimum(x2[i], x2[indexes[1:]])\n",
    "        yy2 = np.minimum(y2[i], y2[indexes[1:]])\n",
    "\n",
    "        w = np.maximum(0, xx2 - xx1)\n",
    "        h = np.maximum(0, yy2 - yy1)\n",
    "\n",
    "        overlap = (w * h) / areas[indexes[1:]]\n",
    "        indexes = np.delete(indexes, np.concatenate(([0], np.where(overlap > overlapThresh)[0] + 1)))\n",
    "\n",
    "    return [boxes[i] for i in picked]"
   ],
   "id": "43206b369962d1f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Detection function",
   "id": "66f44b8251c3b7fe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def detect_faces(image: np.ndarray,\n",
    "                 svm: SVC,\n",
    "                 window_size: Tuple[int, int] = RESOLUTION,\n",
    "                 stepSize: int = 16,\n",
    "                 scale: float = 1.5) -> List[Tuple[int, int, int, int]]:\n",
    "    detections: List[Tuple[int, int, int, int]] = []\n",
    "    for im_scaled in image_pyramid(image, scale=scale, minSize=window_size):\n",
    "        scale_factor: float = image.shape[0] / im_scaled.shape[0]\n",
    "        for (x, y, window) in sliding_window(im_scaled, stepSize, window_size):\n",
    "            if window.shape[0] != window_size[1] or window.shape[1] != window_size[0]:\n",
    "                continue\n",
    "            features: np.ndarray = extract_hog_features(window)\n",
    "            prediction: np.ndarray = svm.predict([features])\n",
    "            if prediction == 1:\n",
    "                detections.append((int(x * scale_factor), int(y * scale_factor),\n",
    "                                   int(window_size[0] * scale_factor), int(window_size[1] * scale_factor)))\n",
    "\n",
    "    return non_max_suppression(detections, overlapThresh=0.3)\n"
   ],
   "id": "22778201b08136bb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Visualization function",
   "id": "ac45fa3e57750522"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def visualize_face_detections(test_image_path: str,\n",
    "                              svm: SVC,\n",
    "                              stepSize: int = 16,\n",
    "                              scale: float = 1.5) -> None:\n",
    "    \"\"\"\n",
    "    Visualizes face detections on a test image using a trained SVM model.\n",
    "\n",
    "    :param test_image_path: Path to the test image.\n",
    "    :param svm: A trained SVC model for face detection.\n",
    "    :param stepSize: The step size for the sliding window.\n",
    "    :param scale: The scaling factor for the image pyramid.\n",
    "    \"\"\"\n",
    "    test_image: Optional[np.ndarray] = cv2.imread(test_image_path)\n",
    "    if test_image is not None:\n",
    "        detections = detect_faces(test_image, svm, stepSize=stepSize, scale=scale)\n",
    "\n",
    "        for (x, y, w, h) in detections:\n",
    "            cv2.rectangle(test_image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(\"Face Detections\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Test image not found.\")"
   ],
   "id": "5b10be83cf3d65df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "visualize_face_detections(\"../test_data/test.jpg\", svc)",
   "id": "b0037a2787e93b05",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
