{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# For any modifications, initially use this notebook as a starting point. Duplicate the notebook and start from there.",
   "id": "e8d6230a66b34623"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Imports",
   "id": "2e3c13fe58bbba2e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T11:46:45.480086Z",
     "start_time": "2025-04-18T11:46:43.671161Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from typing import Generator, List, Optional, Tuple\n",
    "\n",
    "import cv2\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.feature import hog\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from torchvision.datasets import CIFAR10"
   ],
   "id": "db47bd72fb4a4a24",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Constants\n",
   "id": "f3f16a8b88a01e4f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T11:46:45.530860Z",
     "start_time": "2025-04-18T11:46:45.529308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MAX_ITERATIONS: int = 10000\n",
    "RESOLUTION: Tuple[int, int] = (250, 250)"
   ],
   "id": "6cd041df4c21fc43",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# SVC Model",
   "id": "9cebfe581159dd86"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "LFW dataset loading (positive class)",
   "id": "447101bb0a26ea35"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T11:46:45.537878Z",
     "start_time": "2025-04-18T11:46:45.536140Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_lfw_positive_images(target_size: Tuple[int, int] = RESOLUTION) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Loads the LFW dataset, extracts positive images, and resizes them to the target size.\n",
    "\n",
    "    :param target_size: The target size (width, height) for resizing the images.\n",
    "    :return: A tuple containing the NumPy array of resized positive images and the count of positive images.\n",
    "    \"\"\"\n",
    "    lfw = fetch_lfw_people(\n",
    "        color=True,\n",
    "        funneled=True,\n",
    "        resize=1.0\n",
    "    )\n",
    "\n",
    "    pos_img: np.ndarray = np.array([cv2.resize(img, target_size) for img in lfw.images])\n",
    "\n",
    "    return pos_img"
   ],
   "id": "2f2395595188ea67",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "CIFAR-10 dataset loading (negative class)",
   "id": "5718066e5d174747"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T11:46:45.544337Z",
     "start_time": "2025-04-18T11:46:45.542546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_cifar10_negative_images(data_path: str = './data', target_size: Tuple[int, int] = RESOLUTION) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Loads the CIFAR-10 dataset, resizes images to the target size, and extracts negative images as a single NumPy array.\n",
    "\n",
    "    :param data_path: Path to download and store the CIFAR-10 dataset.\n",
    "    :param target_size: The target size (width, height) for resizing the images.\n",
    "    :return: A tuple containing the NumPy array of resized negative images and their count.\n",
    "    \"\"\"\n",
    "    cifar10_dataset = CIFAR10(\n",
    "        root=data_path,\n",
    "        train=True,\n",
    "        download=True\n",
    "    )\n",
    "\n",
    "    neg_img: np.ndarray = np.array([\n",
    "        cv2.resize(np.array(img), target_size) for img, _ in cifar10_dataset\n",
    "    ])\n",
    "\n",
    "    return neg_img"
   ],
   "id": "3d828442360fa9d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "HOG feature extraction (skimage implementation is slow but works well, CV2 is fast but doesn't work well)",
   "id": "ebef3f52b93c7ed0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T11:46:45.551306Z",
     "start_time": "2025-04-18T11:46:45.548767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# def extract_hog_features(image: np.ndarray,\n",
    "#                          pixels_per_cell: Tuple[int, int] = (8, 8),\n",
    "#                          cells_per_block: Tuple[int, int] = (2, 2),\n",
    "#                          orientations: int = 9) -> Tuple[np.ndarray, np.ndarray]:\n",
    "#     \"\"\"\n",
    "#     Extract HOG (Histogram of Oriented Gradients) features using OpenCV's implementation.\n",
    "#\n",
    "#     :param image: The input image as a NumPy array. If color, will be converted to grayscale.\n",
    "#     :param pixels_per_cell: The size of each cell in pixels (width, height).\n",
    "#     :param cells_per_block: The number of cells per block (width, height).\n",
    "#     :param orientations: The number of orientation bins for the histograms.\n",
    "#     :return: The HOG feature vector as a NumPy array.\n",
    "#     \"\"\"\n",
    "#     if len(image.shape) > 2:\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "#\n",
    "#     image_uint8 = image.astype(np.uint8)\n",
    "#\n",
    "#     win_size = image_uint8.shape[::-1]\n",
    "#     block_size = (cells_per_block[1] * pixels_per_cell[1],\n",
    "#                   cells_per_block[0] * pixels_per_cell[0])\n",
    "#     block_stride = (pixels_per_cell[1], pixels_per_cell[0])\n",
    "#     cell_size = (pixels_per_cell[1], pixels_per_cell[0])\n",
    "#\n",
    "#     hog = cv2.HOGDescriptor(_winSize=win_size,\n",
    "#                             _blockSize=block_size,\n",
    "#                             _blockStride=block_stride,\n",
    "#                             _cellSize=cell_size,\n",
    "#                             _nbins=orientations)\n",
    "#\n",
    "#     features = hog.compute(image_uint8)\n",
    "#\n",
    "#     gradient_magnitude = np.zeros_like(image_uint8, dtype=np.float32)\n",
    "#     gradient_angle = np.zeros_like(image_uint8, dtype=np.float32)\n",
    "#\n",
    "#     for y in range(0, image_uint8.shape[0], pixels_per_cell[1]):\n",
    "#         for x in range(0, image_uint8.shape[1], pixels_per_cell[0]):\n",
    "#             cell_features = features[\n",
    "#                 (y // pixels_per_cell[1]) * (image_uint8.shape[1] // pixels_per_cell[0]) + (x // pixels_per_cell[0])\n",
    "#             ]\n",
    "#             gradient_magnitude[y:y + pixels_per_cell[1], x:x + pixels_per_cell[0]] = np.sum(cell_features)\n",
    "#             gradient_angle[y:y + pixels_per_cell[1], x:x + pixels_per_cell[0]] = np.argmax(cell_features)\n",
    "#\n",
    "#     hog_image = cv2.normalize(gradient_magnitude, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "#     return features.flatten(), hog_image\n",
    "\n",
    "def extract_hog_features(image: np.ndarray,\n",
    "                         pixels_per_cell: Tuple[int, int] = (8, 8),\n",
    "                         cells_per_block: Tuple[int, int] = (2, 2),\n",
    "                         orientations: int = 9) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Extracts HOG (Histogram of Oriented Gradients) descriptors from an image.\n",
    "\n",
    "    :param image: The input image as a NumPy array.\n",
    "    :param pixels_per_cell: The size of each cell in pixels (width, height).\n",
    "    :param cells_per_block: The number of cells per block (width, height).\n",
    "    :param orientations: The number of orientation bins for the histograms.\n",
    "    :return: The HOG feature vector and the HOG image as NumPy arrays.\n",
    "    \"\"\"\n",
    "    if len(image.shape) > 2:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    features, hog_image = hog(image, orientations=orientations,\n",
    "                      pixels_per_cell=pixels_per_cell,\n",
    "                      cells_per_block=cells_per_block,\n",
    "                      block_norm='L2-Hys', visualize=True)\n",
    "\n",
    "    return features, hog_image"
   ],
   "id": "7b1facb497952393",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "HOG image visualization",
   "id": "9fb12a60712083fe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T11:46:45.557602Z",
     "start_time": "2025-04-18T11:46:45.555790Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def visualise_hog(image: np.ndarray, hog_image: np.ndarray, cls: str) -> None:\n",
    "    \"\"\"\n",
    "    Visualizes the original and the HOG features of an image.\n",
    "\n",
    "    :param image: The original image as a NumPy array.\n",
    "    :param hog_image: The HOG image as a NumPy array.\n",
    "    \"\"\"\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    ax1.imshow(image, cmap='gray')\n",
    "    ax1.set_title('Original Image')\n",
    "    ax1.axis('off')\n",
    "\n",
    "    ax2.imshow(hog_image, cmap='gray')\n",
    "    ax2.set_title('HOG Visualization')\n",
    "    ax2.axis('off')\n",
    "\n",
    "    plt.suptitle(cls)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "802aad54ada5759f",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Loading the dataset",
   "id": "60a5ab0154a5b667"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T11:46:45.566036Z",
     "start_time": "2025-04-18T11:46:45.562603Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_dataset() -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Load dataset with HOG feature extraction and shuffle the data.\n",
    "    If the dataset is already saved as a CSV file, it loads the data from there.\n",
    "\n",
    "    :return: A tuple containing the shuffled feature matrix (data_X) and the label vector (labels_y).\n",
    "    \"\"\"\n",
    "\n",
    "    csv_path = f'data/dataset{str(RESOLUTION[0])}.csv'\n",
    "\n",
    "    if os.path.exists(csv_path):\n",
    "        df = pd.read_csv(csv_path)\n",
    "        labels_y = df['label'].to_numpy(dtype=np.int32)\n",
    "        data_X = df.drop(columns=['label']).to_numpy(dtype=np.float32)\n",
    "\n",
    "        print(f\"Data loaded from {csv_path}...\")\n",
    "        return data_X, labels_y\n",
    "\n",
    "    print(\"Generating dataset...\")\n",
    "\n",
    "    positive_images: np.ndarray = load_lfw_positive_images(target_size=RESOLUTION)\n",
    "    negative_images: np.ndarray = load_cifar10_negative_images()\n",
    "\n",
    "    total_images = len(positive_images)+ len(negative_images)\n",
    "    feature_length = len(extract_hog_features(positive_images[0])[0])\n",
    "\n",
    "    data_X = np.zeros((total_images, feature_length), dtype=np.float32)\n",
    "    labels_y = np.zeros(total_images, dtype=np.int32)\n",
    "\n",
    "    n_pos = len(positive_images)\n",
    "    labels_y[:n_pos] = 1\n",
    "\n",
    "    for i, img in enumerate(tqdm(positive_images, desc=\"Positive class\", unit=\"img\")):\n",
    "        data_X[i], hog_img = extract_hog_features(img)\n",
    "\n",
    "    for i, img in enumerate(tqdm(negative_images, desc=\"Negative class\", unit=\"img\")):\n",
    "        data_X[i + n_pos], hog_img = extract_hog_features(img)\n",
    "\n",
    "    indices = np.random.permutation(total_images)\n",
    "    data_X = data_X[indices]\n",
    "    labels_y = labels_y[indices]\n",
    "\n",
    "    os.makedirs(os.path.dirname(csv_path), exist_ok=True)\n",
    "    df = pd.DataFrame(data_X)\n",
    "    df['label'] = labels_y\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"Dataset saved to {csv_path}...\")\n",
    "\n",
    "    return data_X, labels_y"
   ],
   "id": "6abbc16d08cd458d",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-04-18T11:46:45.572876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X: np.ndarray\n",
    "Y: np.ndarray\n",
    "X, Y = load_dataset()\n",
    "print(\"Dataset size:\", X.shape, Y.shape)"
   ],
   "id": "250d60d765e072ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Positive class:  17%|█▋        | 2262/13233 [02:32<12:03, 15.16img/s]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Training the SVC (if already trained, it can be loaded from the commented line)",
   "id": "329394b86f7c196e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if not os.path.exists(\"model\"):\n",
    "    os.makedirs(\"model\")\n",
    "\n",
    "filename: str = \"model/svm.joblib\""
   ],
   "id": "89112970c9fb0ad0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# svc: SVC = joblib.load(filename)\n",
    "\n",
    "svc: SVC = SVC(kernel=\"rbf\", max_iter=MAX_ITERATIONS)\n",
    "svc.fit(X, Y)\n",
    "\n",
    "joblib.dump(svc, filename)\n",
    "\n",
    "pred_train: np.ndarray = svc.predict(X)\n",
    "print(\"Classification report (training data):\")\n",
    "print(classification_report(Y, pred_train))"
   ],
   "id": "5b53663f7259fefc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Face detection pipeline",
   "id": "db91c960738b234c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Image pyramid generator, for image scaling",
   "id": "19b7e06dda27db95"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def image_pyramid(image: np.ndarray, scale: float = 1.5, minSize: Tuple[int, int] = RESOLUTION) -> Generator[np.ndarray, None, None]:\n",
    "    \"\"\"\n",
    "    Generates an image pyramid.\n",
    "\n",
    "    :param image: The original image as a NumPy array.\n",
    "    :param scale: The scaling factor for resizing the image.\n",
    "    :param minSize: The minimum size (width, height) at which resizing stops.\n",
    "    :yield: The resized image as a NumPy array.\n",
    "    \"\"\"\n",
    "    yield image\n",
    "    while True:\n",
    "        w: int = int(image.shape[1] / scale)\n",
    "        h: int = int(image.shape[0] / scale)\n",
    "        image = cv2.resize(image, (w, h))\n",
    "        if image.shape[0] < minSize[1] or image.shape[1] < minSize[0]:\n",
    "            break\n",
    "        yield image"
   ],
   "id": "951e1c5e692bc6c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Sliding window generator, for extracting patches from the image",
   "id": "2958cef2e8d46e8a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def sliding_window(image: np.ndarray, stepSize: int, windowSize: Tuple[int, int]) -> Generator[Tuple[int, int, np.ndarray], None, None]:\n",
    "    \"\"\"\n",
    "    Iterates over an image with a sliding window.\n",
    "\n",
    "    :param image: The image to iterate over as a NumPy array.\n",
    "    :param stepSize: The step size for moving the window.\n",
    "    :param windowSize: The size of the window (width, height).\n",
    "    :yield: The coordinates (x, y) and the extracted patch as a NumPy array.\n",
    "    \"\"\"\n",
    "    for y in range(0, image.shape[0] - windowSize[1] + 1, stepSize):\n",
    "        for x in range(0, image.shape[1] - windowSize[0] + 1, stepSize):\n",
    "            yield x, y, image[y:y + windowSize[1], x:x + windowSize[0]]"
   ],
   "id": "685353dd9de7406f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Non-Maximum Suppression (NMS)",
   "id": "72ad9d1a29ebcfb5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def non_max_suppression(boxes: List[Tuple[int, int, int, int]], overlapThresh: float = 0.3) -> List[Tuple[int, int, int, int]]:\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "\n",
    "    boxes_np = np.array(boxes)\n",
    "    x1 = boxes_np[:, 0]\n",
    "    y1 = boxes_np[:, 1]\n",
    "    x2 = x1 + boxes_np[:, 2]\n",
    "    y2 = y1 + boxes_np[:, 3]\n",
    "\n",
    "    areas = (x2 - x1) * (y2 - y1)\n",
    "    indexes = np.argsort(areas)[::-1]\n",
    "\n",
    "    picked = []\n",
    "    while len(indexes) > 0:\n",
    "        i = indexes[0]\n",
    "        picked.append(i)\n",
    "\n",
    "        xx1 = np.maximum(x1[i], x1[indexes[1:]])\n",
    "        yy1 = np.maximum(y1[i], y1[indexes[1:]])\n",
    "        xx2 = np.minimum(x2[i], x2[indexes[1:]])\n",
    "        yy2 = np.minimum(y2[i], y2[indexes[1:]])\n",
    "\n",
    "        w = np.maximum(0, xx2 - xx1)\n",
    "        h = np.maximum(0, yy2 - yy1)\n",
    "\n",
    "        overlap = (w * h) / areas[indexes[1:]]\n",
    "        indexes = np.delete(indexes, np.concatenate(([0], np.where(overlap > overlapThresh)[0] + 1)))\n",
    "\n",
    "    return [boxes[i] for i in picked]"
   ],
   "id": "43206b369962d1f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Detection function",
   "id": "66f44b8251c3b7fe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def detect_faces(image: np.ndarray,\n",
    "                 svm: SVC,\n",
    "                 window_size: Tuple[int, int] = RESOLUTION,\n",
    "                 stepSize: int = 16,\n",
    "                 scale: float = 1.5) -> List[Tuple[int, int, int, int]]:\n",
    "    detections: List[Tuple[int, int, int, int]] = []\n",
    "    for im_scaled in image_pyramid(image, scale=scale, minSize=window_size):\n",
    "        scale_factor: float = image.shape[0] / im_scaled.shape[0]\n",
    "        for (x, y, window) in sliding_window(im_scaled, stepSize, window_size):\n",
    "            if window.shape[0] != window_size[1] or window.shape[1] != window_size[0]:\n",
    "                continue\n",
    "            features: np.ndarray = extract_hog_features(window)\n",
    "            prediction: np.ndarray = svm.predict([features])\n",
    "            if prediction == 1:\n",
    "                detections.append((int(x * scale_factor), int(y * scale_factor),\n",
    "                                   int(window_size[0] * scale_factor), int(window_size[1] * scale_factor)))\n",
    "\n",
    "    return non_max_suppression(detections, overlapThresh=0.3)\n"
   ],
   "id": "22778201b08136bb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Visualization function",
   "id": "ac45fa3e57750522"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def visualize_face_detections(test_image_path: str,\n",
    "                              svm: SVC,\n",
    "                              stepSize: int = 16,\n",
    "                              scale: float = 1.5) -> None:\n",
    "    \"\"\"\n",
    "    Visualizes face detections on a test image using a trained SVM model.\n",
    "\n",
    "    :param test_image_path: Path to the test image.\n",
    "    :param svm: A trained SVC model for face detection.\n",
    "    :param stepSize: The step size for the sliding window.\n",
    "    :param scale: The scaling factor for the image pyramid.\n",
    "    \"\"\"\n",
    "    test_image: Optional[np.ndarray] = cv2.imread(test_image_path)\n",
    "    if test_image is not None:\n",
    "        detections = detect_faces(test_image, svm, stepSize=stepSize, scale=scale)\n",
    "\n",
    "        for (x, y, w, h) in detections:\n",
    "            cv2.rectangle(test_image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(\"Face Detections\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Test image not found.\")"
   ],
   "id": "5b10be83cf3d65df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "visualize_face_detections(\"../test_data/test.jpg\", svc)",
   "id": "b0037a2787e93b05",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
