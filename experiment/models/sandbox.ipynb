{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# TODOs:\n",
    "\n",
    "- explore the possibility of using FDDB dataset or other datasets specifically created for face detection tasks\n",
    "- explore extracting negative class images from positive face bits (in case the first approach doesn't work)\n",
    "- fix OpenCV HOG feature extraction (it doesn't work well, but is significantly faster: ~3 second load_dataset execution time compared to ~ 4 minute)\n",
    "- explore replacing/aiding HOG with PCA\n",
    "- explore other SVCs (poly, radial basis function) and hyperparameters\n",
    "- explore the use of Selective Search or EdgeBoxes for region proposal\n",
    "- explore the use of a Quad Tree and Disjoint Set approach\n",
    "\n",
    "# For any of the above, use this sandbox as a starting point. Duplicate the notebook and start from there."
   ],
   "id": "3719123ed1de8d18"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Imports",
   "id": "2d95fbd2bc4ede3f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T13:53:09.794798Z",
     "start_time": "2025-04-17T13:53:08.164833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from typing import Generator, List, Optional, Tuple\n",
    "\n",
    "import cv2\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from torchvision.datasets import CIFAR10"
   ],
   "id": "9d117d5672e307e4",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Constants\n",
   "id": "3c496b6bcbe12098"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T13:53:09.895904Z",
     "start_time": "2025-04-17T13:53:09.894386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MAX_ITERATIONS: int = 10000\n",
    "RESOLUTION: Tuple[int, int] = (64, 64)"
   ],
   "id": "257c54afc37fc9d8",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Image pyramid generator, for image scaling",
   "id": "fa80a73c225115e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T13:53:09.944427Z",
     "start_time": "2025-04-17T13:53:09.942231Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def image_pyramid(image: np.ndarray, scale: float = 1.5, minSize: Tuple[int, int] = RESOLUTION) -> Generator[np.ndarray, None, None]:\n",
    "    \"\"\"\n",
    "    Generates an image pyramid.\n",
    "\n",
    "    :param image: The original image as a NumPy array.\n",
    "    :param scale: The scaling factor for resizing the image.\n",
    "    :param minSize: The minimum size (width, height) at which resizing stops.\n",
    "    :yield: The resized image as a NumPy array.\n",
    "    \"\"\"\n",
    "    yield image\n",
    "    while True:\n",
    "        w: int = int(image.shape[1] / scale)\n",
    "        h: int = int(image.shape[0] / scale)\n",
    "        image = cv2.resize(image, (w, h))\n",
    "        if image.shape[0] < minSize[1] or image.shape[1] < minSize[0]:\n",
    "            break\n",
    "        yield image"
   ],
   "id": "f0f67448afe76783",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Sliding window generator, for extracting patches from the image",
   "id": "918fa8b90db780e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T13:53:09.989153Z",
     "start_time": "2025-04-17T13:53:09.986737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sliding_window(image: np.ndarray, stepSize: int, windowSize: Tuple[int, int]) -> Generator[Tuple[int, int, np.ndarray], None, None]:\n",
    "    \"\"\"\n",
    "    Iterates over an image with a sliding window.\n",
    "\n",
    "    :param image: The image to iterate over as a NumPy array.\n",
    "    :param stepSize: The step size for moving the window.\n",
    "    :param windowSize: The size of the window (width, height).\n",
    "    :yield: The coordinates (x, y) and the extracted patch as a NumPy array.\n",
    "    \"\"\"\n",
    "    for y in range(0, image.shape[0] - windowSize[1] + 1, stepSize):\n",
    "        for x in range(0, image.shape[1] - windowSize[0] + 1, stepSize):\n",
    "            yield x, y, image[y:y + windowSize[1], x:x + windowSize[0]]"
   ],
   "id": "be1348d86cdb3c8c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "HOG feature extraction (skimage implementation is slow but works well, CV2 is fast but doesn't work well)",
   "id": "8332c9fe5c8f81cb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T13:53:10.034159Z",
     "start_time": "2025-04-17T13:53:10.031257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# def extract_hog_features(image: np.ndarray,\n",
    "#                          pixels_per_cell: Tuple[int, int] = (8, 8),\n",
    "#                          cells_per_block: Tuple[int, int] = (2, 2),\n",
    "#                          orientations: int = 9) -> np.ndarray:\n",
    "#     \"\"\"\n",
    "#     Extract HOG (Histogram of Oriented Gradients) features using OpenCV's implementation.\n",
    "#\n",
    "#     :param image: The input image as a NumPy array. If color, will be converted to grayscale.\n",
    "#     :param pixels_per_cell: The size of each cell in pixels (width, height).\n",
    "#     :param cells_per_block: The number of cells per block (width, height).\n",
    "#     :param orientations: The number of orientation bins for the histograms.\n",
    "#     :return: The HOG feature vector as a NumPy array.\n",
    "#     \"\"\"\n",
    "#     if len(image.shape) > 2:\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "#\n",
    "#     image_uint8 = image.astype(np.uint8)\n",
    "#\n",
    "#     win_size = image_uint8.shape[::-1]\n",
    "#     block_size = (cells_per_block[1] * pixels_per_cell[1],\n",
    "#                   cells_per_block[0] * pixels_per_cell[0])\n",
    "#     block_stride = (pixels_per_cell[1], pixels_per_cell[0])\n",
    "#     cell_size = (pixels_per_cell[1], pixels_per_cell[0])\n",
    "#\n",
    "#     hog = cv2.HOGDescriptor(_winSize=win_size,\n",
    "#                             _blockSize=block_size,\n",
    "#                             _blockStride=block_stride,\n",
    "#                             _cellSize=cell_size,\n",
    "#                             _nbins=orientations)\n",
    "#\n",
    "#     features = hog.compute(image_uint8)\n",
    "#     return features.flatten()\n",
    "\n",
    "def extract_hog_features(image: np.ndarray,\n",
    "                         pixels_per_cell: Tuple[int, int] = (8, 8),\n",
    "                         cells_per_block: Tuple[int, int] = (2, 2),\n",
    "                         orientations: int = 9) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extracts HOG (Histogram of Oriented Gradients) descriptors from an image.\n",
    "\n",
    "    :param image: The input image as a NumPy array.\n",
    "    :param pixels_per_cell: The size of each cell in pixels (width, height).\n",
    "    :param cells_per_block: The number of cells per block (width, height).\n",
    "    :param orientations: The number of orientation bins for the histograms.\n",
    "    :return: The HOG feature vector as a NumPy array.\n",
    "    \"\"\"\n",
    "    if len(image.shape) > 2:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    features, _ = hog(image, orientations=orientations,\n",
    "                      pixels_per_cell=pixels_per_cell,\n",
    "                      cells_per_block=cells_per_block,\n",
    "                      block_norm='L2-Hys', visualize=True)\n",
    "    return features"
   ],
   "id": "6205b12d8485a3d4",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "LFW dataset loading (positive class)",
   "id": "c35b63ecb9c8fa41"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T13:53:10.078528Z",
     "start_time": "2025-04-17T13:53:10.076466Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_lfw_positive_images(target_size: Tuple[int, int] = RESOLUTION) -> Tuple[np.ndarray, int]:\n",
    "    \"\"\"\n",
    "    Loads the LFW dataset, extracts positive images, and resizes them to the target size.\n",
    "\n",
    "    :param target_size: The target size (width, height) for resizing the images.\n",
    "    :return: A tuple containing the NumPy array of resized positive images and the count of positive images.\n",
    "    \"\"\"\n",
    "    lfw = fetch_lfw_people(color=True, funneled=True, resize=1.0)\n",
    "    pos_img: np.ndarray = lfw.images\n",
    "    pos_cnt: int = pos_img.shape[0]\n",
    "\n",
    "    pos_resized: np.ndarray = np.array([cv2.resize(img, target_size) for img in pos_img])\n",
    "    return pos_resized, pos_cnt"
   ],
   "id": "64df852ac8f0ef59",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T13:53:14.190990Z",
     "start_time": "2025-04-17T13:53:10.128141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "positive_images: np.ndarray\n",
    "positive_count: int\n",
    "positive_images, positive_count = load_lfw_positive_images(target_size=RESOLUTION)\n",
    "print(positive_count)"
   ],
   "id": "76b1475389641931",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13233\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "CIFAR-10 dataset loading (negative class)",
   "id": "8f17c4099953c073"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T13:53:14.197126Z",
     "start_time": "2025-04-17T13:53:14.194959Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_cifar10_negative_images(data_path: str = './data', target_size: Tuple[int, int] = RESOLUTION) -> Tuple[np.ndarray, int]:\n",
    "    \"\"\"\n",
    "    Loads the CIFAR-10 dataset, resizes images to the target size, and extracts negative images as a single NumPy array.\n",
    "\n",
    "    :param data_path: Path to download and store the CIFAR-10 dataset.\n",
    "    :param target_size: The target size (width, height) for resizing the images.\n",
    "    :return: A tuple containing the NumPy array of resized negative images and their count.\n",
    "    \"\"\"\n",
    "    cifar10_dataset = CIFAR10(\n",
    "        root=data_path,\n",
    "        train=True,\n",
    "        download=True\n",
    "    )\n",
    "\n",
    "    neg_img: np.ndarray = np.array([\n",
    "        cv2.resize(np.array(img), target_size) for img, _ in cifar10_dataset\n",
    "    ])\n",
    "    neg_cnt: int = len(neg_img)\n",
    "\n",
    "    return neg_img, neg_cnt"
   ],
   "id": "d6da6d1bf0c433b4",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T13:53:16.076166Z",
     "start_time": "2025-04-17T13:53:14.244205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "negative_images: np.ndarray\n",
    "negative_count: int\n",
    "negative_images, negative_count = load_cifar10_negative_images()\n",
    "print(negative_count)"
   ],
   "id": "4c4d753f628bd20f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Loading the dataset",
   "id": "660ae598a43ee6c6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T13:53:16.081647Z",
     "start_time": "2025-04-17T13:53:16.078795Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_dataset(pos_img: np.ndarray,\n",
    "                 neg_img: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Load dataset with optimized parallel HOG feature extraction.\n",
    "\n",
    "    :param pos_img: Array of positive class images.\n",
    "    :param neg_img: Array of negative class images.\n",
    "    :return: A tuple containing the feature matrix (data_X) and the label vector (labels_y).\n",
    "    \"\"\"\n",
    "    total_images = len(pos_img) + len(neg_img)\n",
    "    feature_length = len(extract_hog_features(pos_img[0]))\n",
    "\n",
    "    data_X = np.zeros((total_images, feature_length), dtype=np.float32)\n",
    "    labels_y = np.zeros(total_images, dtype=np.int32)\n",
    "\n",
    "    n_pos = len(pos_img)\n",
    "    for i, img in enumerate(pos_img):\n",
    "        data_X[i] = extract_hog_features(img)\n",
    "\n",
    "    labels_y[:n_pos] = 1\n",
    "\n",
    "    for i, img in enumerate(neg_img):\n",
    "        data_X[i + n_pos] = extract_hog_features(img)\n",
    "\n",
    "    return data_X, labels_y"
   ],
   "id": "854ec735de9fd79a",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T13:56:40.423462Z",
     "start_time": "2025-04-17T13:53:44.267809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X: np.ndarray\n",
    "Y: np.ndarray\n",
    "X, Y = load_dataset(positive_images, negative_images)\n",
    "print(\"Dataset size:\", X.shape, Y.shape)"
   ],
   "id": "f261a30104e345b9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: (63233, 1764) (63233,)\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T13:56:40.474350Z",
     "start_time": "2025-04-17T13:56:40.472306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if not os.path.exists(\"model\"):\n",
    "    os.makedirs(\"model\")\n",
    "\n",
    "filename: str = \"model/svm.joblib\""
   ],
   "id": "3316013d68cfc07c",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Training the SVC (already trained, can be loaded from the commented line)",
   "id": "a110568c9a13aa9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T13:59:14.019837Z",
     "start_time": "2025-04-17T13:56:40.520055Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# svc: SVC = joblib.load(filename)\n",
    "\n",
    "svc: SVC = SVC(kernel=\"rbf\", max_iter=MAX_ITERATIONS)\n",
    "svc.fit(X, Y)\n",
    "\n",
    "joblib.dump(svc, filename)\n",
    "\n",
    "pred_train: np.ndarray = svc.predict(X)\n",
    "print(\"Classification report (training data):\")\n",
    "print(classification_report(Y, pred_train))"
   ],
   "id": "75250915849ec177",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report (training data):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     50000\n",
      "           1       1.00      1.00      1.00     13233\n",
      "\n",
      "    accuracy                           1.00     63233\n",
      "   macro avg       1.00      1.00      1.00     63233\n",
      "weighted avg       1.00      1.00      1.00     63233\n",
      "\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Non-Maximum Suppression (NMS)",
   "id": "9b60729e366f1717"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T13:59:34.240750Z",
     "start_time": "2025-04-17T13:59:34.236356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def non_max_suppression(boxes: List[Tuple[int, int, int, int]], overlapThresh: float = 0.3) -> List[Tuple[int, int, int, int]]:\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "\n",
    "    boxes_np = np.array(boxes)\n",
    "    x1 = boxes_np[:, 0]\n",
    "    y1 = boxes_np[:, 1]\n",
    "    x2 = x1 + boxes_np[:, 2]\n",
    "    y2 = y1 + boxes_np[:, 3]\n",
    "\n",
    "    areas = (x2 - x1) * (y2 - y1)\n",
    "    indexes = np.argsort(areas)[::-1]\n",
    "\n",
    "    picked = []\n",
    "    while len(indexes) > 0:\n",
    "        i = indexes[0]\n",
    "        picked.append(i)\n",
    "\n",
    "        xx1 = np.maximum(x1[i], x1[indexes[1:]])\n",
    "        yy1 = np.maximum(y1[i], y1[indexes[1:]])\n",
    "        xx2 = np.minimum(x2[i], x2[indexes[1:]])\n",
    "        yy2 = np.minimum(y2[i], y2[indexes[1:]])\n",
    "\n",
    "        w = np.maximum(0, xx2 - xx1)\n",
    "        h = np.maximum(0, yy2 - yy1)\n",
    "\n",
    "        overlap = (w * h) / areas[indexes[1:]]\n",
    "        indexes = np.delete(indexes, np.concatenate(([0], np.where(overlap > overlapThresh)[0] + 1)))\n",
    "\n",
    "    return [boxes[i] for i in picked]"
   ],
   "id": "46d032786cc68cff",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Detection function",
   "id": "f7e27993d908e4a9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T13:59:34.285482Z",
     "start_time": "2025-04-17T13:59:34.282358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def detect_faces(image: np.ndarray,\n",
    "                 svm: SVC,\n",
    "                 window_size: Tuple[int, int] = RESOLUTION,\n",
    "                 stepSize: int = 16,\n",
    "                 scale: float = 1.5) -> List[Tuple[int, int, int, int]]:\n",
    "    detections: List[Tuple[int, int, int, int]] = []\n",
    "    for im_scaled in image_pyramid(image, scale=scale, minSize=window_size):\n",
    "        scale_factor: float = image.shape[0] / im_scaled.shape[0]\n",
    "        for (x, y, window) in sliding_window(im_scaled, stepSize, window_size):\n",
    "            if window.shape[0] != window_size[1] or window.shape[1] != window_size[0]:\n",
    "                continue\n",
    "            features: np.ndarray = extract_hog_features(window)\n",
    "            prediction: np.ndarray = svm.predict([features])\n",
    "            if prediction == 1:\n",
    "                detections.append((int(x * scale_factor), int(y * scale_factor),\n",
    "                                   int(window_size[0] * scale_factor), int(window_size[1] * scale_factor)))\n",
    "\n",
    "    return non_max_suppression(detections, overlapThresh=0.3)\n"
   ],
   "id": "d2fcf6930da90a0c",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Visualization function",
   "id": "4cfaf35f76c79b75"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T13:59:34.362267Z",
     "start_time": "2025-04-17T13:59:34.357160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def visualize_face_detections(test_image_path: str,\n",
    "                              svm: SVC,\n",
    "                              stepSize: int = 16,\n",
    "                              scale: float = 1.5) -> None:\n",
    "    \"\"\"\n",
    "    Visualizes face detections on a test image using a trained SVM model.\n",
    "\n",
    "    :param test_image_path: Path to the test image.\n",
    "    :param svm: A trained SVC model for face detection.\n",
    "    :param stepSize: The step size for the sliding window.\n",
    "    :param scale: The scaling factor for the image pyramid.\n",
    "    \"\"\"\n",
    "    test_image: Optional[np.ndarray] = cv2.imread(test_image_path)\n",
    "    if test_image is not None:\n",
    "        detections = detect_faces(test_image, svm, stepSize=stepSize, scale=scale)\n",
    "\n",
    "        for (x, y, w, h) in detections:\n",
    "            cv2.rectangle(test_image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(\"Face Detections\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Test image not found.\")"
   ],
   "id": "8d7ece690223201b",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-04-17T13:59:34.408188Z"
    }
   },
   "cell_type": "code",
   "source": "visualize_face_detections(\"../test_data/test.jpg\", svc)",
   "id": "5afe7b7b8fbd14f9",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
